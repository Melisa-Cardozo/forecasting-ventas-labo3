{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd1cda0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   periodo  customer_id  product_id  plan_precios_cuidados  cust_request_qty  \\\n",
      "0   201701        10234       20524                      0                 2   \n",
      "1   201701        10032       20524                      0                 1   \n",
      "2   201701        10217       20524                      0                 1   \n",
      "3   201701        10125       20524                      0                 1   \n",
      "4   201701        10012       20524                      0                11   \n",
      "\n",
      "   cust_request_tn       tn  \n",
      "0          0.05300  0.05300  \n",
      "1          0.13628  0.13628  \n",
      "2          0.03028  0.03028  \n",
      "3          0.02271  0.02271  \n",
      "4          1.54452  1.54452  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta al archivo en tu m√°quina (us√° la r al principio para que tome bien las barras)\n",
    "ruta_archivo = r'C:\\Maestria\\Labo 3\\sell-in.txt'\n",
    "\n",
    "# Intentamos leer el archivo con autodetecci√≥n de separador\n",
    "df = pd.read_csv(ruta_archivo, sep=None, engine='python')\n",
    "\n",
    "# Mostramos las primeras filas\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db226063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è  Prediciendo para el periodo 202001\n",
      "‚úÖ Archivo guardado en C:\\Maestria\\Labo 3\\submission.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import zipfile\n",
    "\n",
    "#------------- CONFIG -----------------\n",
    "RUTA_VENTAS      = Path(r\"C:\\Maestria\\Labo 3\\sell-in.txt\")    # archivo hist√≥rico\n",
    "RUTA_ZIP         = Path(r\"C:\\Maestria\\Labo 3\\Zip-tb.zip\")     # contiene tb_productos.txt\n",
    "NOMBRE_TXT_PROD  = \"tb_productos.txt\"                         # dentro del zip\n",
    "WINDOW_MESES     = 3                                          # promedio simple de N √∫ltimos meses\n",
    "RUTA_SALIDA_CSV  = Path(r\"C:\\Maestria\\Labo 3\\submission.csv\")\n",
    "#--------------------------------------\n",
    "\n",
    "# 1) ------------------ Leer datasets ------------------\n",
    "# Ventas\n",
    "df = pd.read_csv(RUTA_VENTAS, sep=None, engine=\"python\")   # autodetecta tab, coma, etc.\n",
    "\n",
    "# Lista de los 780 productos\n",
    "with zipfile.ZipFile(RUTA_ZIP) as z:\n",
    "    with z.open(NOMBRE_TXT_PROD) as f:\n",
    "        productos = pd.read_csv(f, sep=None, engine=\"python\")\n",
    "\n",
    "# 2) ------- Dejar s√≥lo columnas clave y tipar ---------\n",
    "df = df[['periodo', 'product_id', 'tn']].copy()\n",
    "df['periodo'] = df['periodo'].astype(str).str.zfill(6)        # 202504 ‚Üí string ‚Äò202504‚Äô\n",
    "df['anio']    = df['periodo'].str[:4].astype(int)\n",
    "df['mes']     = df['periodo'].str[4:6].astype(int)\n",
    "\n",
    "# 3) ---------- Detectar √∫ltimo periodo  --------------\n",
    "ultimo_anio, ultimo_mes = df[['anio','mes']].max().tolist()\n",
    "# mes siguiente\n",
    "if ultimo_mes == 12:\n",
    "    prox_anio, prox_mes = ultimo_anio + 1, 1\n",
    "else:\n",
    "    prox_anio, prox_mes = ultimo_anio, ultimo_mes + 1\n",
    "target_periodo_str = f\"{prox_anio}{prox_mes:02d}\"\n",
    "print(f\"‚öôÔ∏è  Prediciendo para el periodo {target_periodo_str}\")\n",
    "\n",
    "# 4) ---------- Agregar ventas por producto -----------\n",
    "# Ordenar por fecha para el rolling\n",
    "df['fecha_idx'] = pd.to_datetime(df['anio'].astype(str) + df['mes'].astype(str) + '01', format=\"%Y%m%d\")\n",
    "ventas_mensuales = (df.groupby(['product_id', 'fecha_idx'])['tn']\n",
    "                      .sum()\n",
    "                      .sort_index()\n",
    "                      .groupby(level=0))\n",
    "\n",
    "# 5) ---------- Baseline: media √∫ltimos N meses --------\n",
    "# Calculamos rolling window hacia atr√°s\n",
    "predicciones = (ventas_mensuales\n",
    "                .apply(lambda s: s.tail(WINDOW_MESES).mean())\n",
    "                .reset_index()\n",
    "                .groupby('product_id', as_index=False)['tn']\n",
    "                .last())\n",
    "\n",
    "# 6) ---------- Garantizar 780 filas -------------------\n",
    "predicciones = productos[['product_id']].merge(predicciones, on='product_id', how='left')\n",
    "predicciones['tn'] = predicciones['tn'].fillna(0)   # productos sin ventas recientes ‚áí 0\n",
    "\n",
    "# 7) ---------- Formatear decimales & guardar ----------\n",
    "predicciones['tn'] = predicciones['tn'].round(5)\n",
    "predicciones.to_csv(RUTA_SALIDA_CSV, index=False, float_format=\"%.5f\")\n",
    "\n",
    "print(f\"‚úÖ Archivo guardado en {RUTA_SALIDA_CSV.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4e6cea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediciendo para 202001\n",
      "CSV generado: C:\\Maestria\\Labo 3\\submission.csv ‚Äî filas: 780\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "RUTA_VENTAS      = Path(r\"C:\\Maestria\\Labo 3\\sell-in.txt\")\n",
    "RUTA_ZIP         = Path(r\"C:\\Maestria\\Labo 3\\Zip-tb.zip\")\n",
    "NOMBRE_TXT_PROD  = \"tb_productos.txt\"\n",
    "WINDOW_MESES     = 3                                  # media m√≥vil de N meses\n",
    "RUTA_SALIDA_CSV  = Path(r\"C:\\Maestria\\Labo 3\\submission.csv\")\n",
    "# ----------------------------\n",
    "\n",
    "# 1) Leer ventas\n",
    "df = pd.read_csv(RUTA_VENTAS, sep=None, engine=\"python\")\n",
    "\n",
    "# 2) Leer lista de todos los productos (por si hay metadatos √∫tiles)\n",
    "with zipfile.ZipFile(RUTA_ZIP) as z:\n",
    "    with z.open(NOMBRE_TXT_PROD) as f:\n",
    "        df_prod = pd.read_csv(f, sep=None, engine=\"python\")\n",
    "\n",
    "# 3) Arreglar fechas\n",
    "df['periodo'] = df['periodo'].astype(str).str.zfill(6)\n",
    "df['anio']    = df['periodo'].str[:4].astype(int)\n",
    "df['mes']     = df['periodo'].str[4:6].astype(int)\n",
    "df['fecha']   = pd.to_datetime(df['anio'].astype(str)+df['mes'].astype(str)+'01', format='%Y%m%d')\n",
    "\n",
    "# 4) Detectar pr√≥ximo mes\n",
    "ult_a, ult_m = df[['anio','mes']].max()\n",
    "prox_a, prox_m = (ult_a + 1, 1) if ult_m == 12 else (ult_a, ult_m + 1)\n",
    "print(f\"Prediciendo para {prox_a}{prox_m:02d}\")\n",
    "\n",
    "# 5) TOP-779 por tn acumulada\n",
    "top_ids = (df.groupby('product_id')['tn']\n",
    "             .sum()\n",
    "             .sort_values(ascending=False)\n",
    "             .head(779)\n",
    "             .index)\n",
    "\n",
    "# 6) Serie mensual por SKU\n",
    "df_top = df[df['product_id'].isin(top_ids)]\n",
    "serie = (df_top.groupby(['product_id', 'fecha'])['tn']\n",
    "               .sum()\n",
    "               .sort_index()\n",
    "               .groupby(level=0))\n",
    "\n",
    "# 7) Baseline: media √∫ltimos N meses\n",
    "pred = (serie.apply(lambda s: s.tail(WINDOW_MESES).mean())\n",
    "              .reset_index()\n",
    "              .groupby('product_id', as_index=False)['tn']\n",
    "              .last())\n",
    "\n",
    "# 8) Asegurar exactamente 779 filas (ya lo son) y formateo\n",
    "pred['tn'] = pred['tn'].fillna(0).round(5)\n",
    "pred = pred.sort_values('product_id')            # orden opcional\n",
    "assert len(pred) == 779, \"Debe haber 779 productos\"\n",
    "\n",
    "# 9) Guardar CSV\n",
    "pred.to_csv(RUTA_SALIDA_CSV, index=False, float_format=\"%.5f\")\n",
    "print(f\"CSV generado: {RUTA_SALIDA_CSV} ‚Äî filas: {len(pred)+1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd2efe05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÜ Prediciendo para: 202001\n",
      "‚úÖ CSV generado en C:\\Maestria\\Labo 3\\submission_t780.csv ‚Äî filas (sin encabezado): 780\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "\n",
    "# ---------- CONFIGURA RUTAS ----------\n",
    "RUTA_VENTAS      = Path(r\"C:\\Maestria\\Labo 3\\sell-in.txt\")\n",
    "RUTA_ZIP         = Path(r\"C:\\Maestria\\Labo 3\\Zip-tb.zip\")\n",
    "TXT_PRODUCTOS    = \"tb_productos.txt\"        # nombre dentro del ZIP\n",
    "WINDOW_MESES     = 3                         # media m√≥vil simple\n",
    "RUTA_SALIDA_CSV  = Path(r\"C:\\Maestria\\Labo 3\\submission_t780.csv\")\n",
    "# --------------------------------------\n",
    "\n",
    "# 1) Leer ventas\n",
    "df = pd.read_csv(RUTA_VENTAS, sep=None, engine=\"python\")\n",
    "\n",
    "# 2) Leer lista de productos (por si la necesit√°s m√°s adelante)\n",
    "with zipfile.ZipFile(RUTA_ZIP) as z:\n",
    "    with z.open(TXT_PRODUCTOS) as f:\n",
    "        _ = pd.read_csv(f, sep=None, engine=\"python\")   # no la usamos ahora\n",
    "\n",
    "# 3) Preparar campo fecha\n",
    "df['periodo'] = df['periodo'].astype(str).str.zfill(6)\n",
    "df['anio']    = df['periodo'].str[:4].astype(int)\n",
    "df['mes']     = df['periodo'].str[4:6].astype(int)\n",
    "df['fecha']   = pd.to_datetime(df['anio'].astype(str)+df['mes'].astype(str)+'01', format='%Y%m%d')\n",
    "\n",
    "# 4) Detecci√≥n del pr√≥ximo mes (solo para informaci√≥n)\n",
    "ult_a, ult_m = df[['anio','mes']].max()\n",
    "prox_a, prox_m = (ult_a + 1, 1) if ult_m == 12 else (ult_a, ult_m + 1)\n",
    "print(f\"üìÜ Prediciendo para: {prox_a}{prox_m:02d}\")\n",
    "\n",
    "# 5) Top-780 por venta total (tn acumulada)\n",
    "top_ids = (df.groupby('product_id')['tn']\n",
    "             .sum()\n",
    "             .sort_values(ascending=False)\n",
    "             .head(780)         # ‚Üê‚Äì‚Äì AHORA 780\n",
    "             .index)\n",
    "\n",
    "# 6) Serie mensual por SKU (solo top)\n",
    "df_top = df[df['product_id'].isin(top_ids)]\n",
    "serie  = (df_top.groupby(['product_id', 'fecha'])['tn']\n",
    "                .sum()\n",
    "                .sort_index()\n",
    "                .groupby(level=0))\n",
    "\n",
    "# 7) Predicci√≥n baseline: media de los √∫ltimos N meses\n",
    "pred = (serie.apply(lambda s: s.tail(WINDOW_MESES).mean())\n",
    "              .reset_index()\n",
    "              .groupby('product_id', as_index=False)['tn']\n",
    "              .last())\n",
    "\n",
    "# 8) Garantizar exactamente 780 filas\n",
    "pred['tn'] = pred['tn'].fillna(0).round(5)\n",
    "assert len(pred) == 780, f\"Se esperaban 780 filas y hay {len(pred)}\"\n",
    "\n",
    "# 9) Guardar CSV final\n",
    "pred.to_csv(RUTA_SALIDA_CSV, index=False, float_format=\"%.5f\")\n",
    "print(f\"‚úÖ CSV generado en {RUTA_SALIDA_CSV.resolve()} ‚Äî filas (sin encabezado): {len(pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98a88257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¢ Filas totales en tb_productos:        1251\n",
      "üî¢ product_id √∫nicos en tb_productos:    1251\n",
      "¬øHay ids duplicados?  False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "# ‚ñ∏ Rutas ------------------------------------------------------------------\n",
    "ZIP_PROD   = Path(r\"C:\\Maestria\\Labo 3\\Zip-tb.zip\")   # el zip que subiste\n",
    "TXT_INSIDE = \"tb_productos.txt\"                       # nombre dentro del zip\n",
    "SUB_FILE   = Path(r\"C:\\Maestria\\Labo 3\\submission_t780.csv\")  # tu submission\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "# 1) Leer tb_productos.txt desde el ZIP\n",
    "with zipfile.ZipFile(ZIP_PROD) as z:\n",
    "    with z.open(TXT_INSIDE) as f:\n",
    "        prod = pd.read_csv(f, sep=None, engine=\"python\")   # autodetecta tab, coma‚Ä¶\n",
    "\n",
    "print(f\"üî¢ Filas totales en tb_productos:        {len(prod)}\")\n",
    "print(f\"üî¢ product_id √∫nicos en tb_productos:    {prod['product_id'].nunique()}\")\n",
    "print(f\"¬øHay ids duplicados?  {len(prod) != prod['product_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf8cc14",
   "metadata": {},
   "source": [
    "Primer codigo que anda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31efefce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÜ Prediciendo para: 202001\n",
      "‚úÖ CSV generado en C:\\Maestria\\Labo 3\\submission_t780.csv ‚Äî filas (sin encabezado): 780\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ CONFIG ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "RUTA_VENTAS      = Path(r\"C:\\Maestria\\Labo 3\\sell-in.txt\")\n",
    "RUTA_LISTA_780   = Path(r\"C:\\Maestria\\Labo 3\\780_a_predecir.txt\")\n",
    "WINDOW_MESES     = 3                              # media m√≥vil simple\n",
    "RUTA_SALIDA_CSV  = Path(r\"C:\\Maestria\\Labo 3\\submission_t780.csv\")\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "\n",
    "# 1) Leer hist√≥rico de ventas\n",
    "df = pd.read_csv(RUTA_VENTAS, sep=None, engine=\"python\")\n",
    "\n",
    "\n",
    "# 2) Leer lista exacta de 780 product_id  (l√≠nea por l√≠nea)\n",
    "product_ids = []\n",
    "with open(RUTA_LISTA_780, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line or line.lower().startswith('product'):\n",
    "            continue            # salta encabezado o l√≠neas vac√≠as\n",
    "        product_ids.append(int(line))\n",
    "\n",
    "assert len(product_ids) == 780, f\"La lista deber√≠a tener 780 ids y tiene {len(product_ids)}\"\n",
    "lista = pd.DataFrame({'product_id': product_ids})\n",
    "\n",
    "\n",
    "# 3) Preparar campo fecha\n",
    "df['periodo'] = df['periodo'].astype(str).str.zfill(6)\n",
    "df['anio']    = df['periodo'].str[:4].astype(int)\n",
    "df['mes']     = df['periodo'].str[4:6].astype(int)\n",
    "df['fecha']   = pd.to_datetime(df['anio'].astype(str) + df['mes'].astype(str) + '01',\n",
    "                               format='%Y%m%d')\n",
    "\n",
    "\n",
    "# 4) Detecci√≥n del pr√≥ximo mes (solo info)\n",
    "ult_a, ult_m = df[['anio','mes']].max()\n",
    "prox_a, prox_m = (ult_a + 1, 1) if ult_m == 12 else (ult_a, ult_m + 1)\n",
    "print(f\"üìÜ Prediciendo para: {prox_a}{prox_m:02d}\")\n",
    "\n",
    "\n",
    "# 5) Filtrar s√≥lo los 780 SKU\n",
    "df_780 = df[df['product_id'].isin(product_ids)]\n",
    "\n",
    "\n",
    "# 6) Serie mensual por SKU\n",
    "serie = (df_780\n",
    "         .groupby(['product_id', 'fecha'])['tn']\n",
    "         .sum()\n",
    "         .sort_index()\n",
    "         .groupby(level=0))\n",
    "\n",
    "\n",
    "# 7) Predicci√≥n baseline: media de los √∫ltimos N meses\n",
    "pred = (serie.apply(lambda s: s.tail(WINDOW_MESES).mean())\n",
    "              .reset_index()\n",
    "              .groupby('product_id', as_index=False)['tn']\n",
    "              .last())\n",
    "\n",
    "\n",
    "# 8) Unir con la lista y rellenar faltantes con 0\n",
    "pred = lista.merge(pred, on='product_id', how='left')\n",
    "pred['tn'] = pred['tn'].fillna(0).round(5)\n",
    "\n",
    "assert len(pred) == 780, f\"Se esperaban 780 filas y hay {len(pred)}\"\n",
    "\n",
    "\n",
    "# 9) Guardar CSV final\n",
    "pred.to_csv(RUTA_SALIDA_CSV, index=False, float_format=\"%.5f\")\n",
    "print(f\"‚úÖ CSV generado en {RUTA_SALIDA_CSV.resolve()} ‚Äî filas (sin encabezado): {len(pred)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a10ffc9",
   "metadata": {},
   "source": [
    "1, 3, 6, 9, 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42f37170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CSV ventana 1 guardado en submission_t780_win1.csv\n",
      "‚úÖ CSV ventana 3 guardado en submission_t780_win3.csv\n",
      "‚úÖ CSV ventana 6 guardado en submission_t780_win6.csv\n",
      "‚úÖ CSV ventana 9 guardado en submission_t780_win9.csv\n",
      "‚úÖ CSV ventana 12 guardado en submission_t780_win12.csv\n",
      "üèÅ Listo: se generaron los 5 archivos.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ CONFIG ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "RUTA_VENTAS     = Path(r\"C:\\Maestria\\Labo 3\\sell-in.txt\")\n",
    "RUTA_LISTA_780  = Path(r\"C:\\Maestria\\Labo 3\\780_a_predecir.txt\")\n",
    "WINDOWS         = [1, 3, 6, 9, 12]                 # medias m√≥viles a generar\n",
    "CARPETA_SALIDA  = Path(r\"C:\\Maestria\\Labo 3\")      # misma carpeta\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "\n",
    "# 1) Leer hist√≥rico de ventas\n",
    "df = pd.read_csv(RUTA_VENTAS, sep=None, engine=\"python\")\n",
    "\n",
    "# 2) Leer lista exacta de 780 product_id  (l√≠nea por l√≠nea)\n",
    "with open(RUTA_LISTA_780, 'r', encoding='utf-8') as f:\n",
    "    product_ids = [int(line.strip()) for line in f\n",
    "                   if line.strip() and not line.lower().startswith('product')]\n",
    "\n",
    "assert len(product_ids) == 780, \"La lista debe tener 780 ids\"\n",
    "lista = pd.DataFrame({'product_id': product_ids})\n",
    "\n",
    "# 3) Preparar campo fecha\n",
    "df['periodo'] = df['periodo'].astype(str).str.zfill(6)\n",
    "df['anio']    = df['periodo'].str[:4].astype(int)\n",
    "df['mes']     = df['periodo'].str[4:6].astype(int)\n",
    "df['fecha']   = pd.to_datetime(\n",
    "    df['anio'].astype(str) + df['mes'].astype(str) + '01', format='%Y%m%d'\n",
    ")\n",
    "\n",
    "# 4) Filtrar s√≥lo los 780 SKU\n",
    "df = df[df['product_id'].isin(product_ids)]\n",
    "\n",
    "# 5) Serie mensual por SKU\n",
    "serie = (df.groupby(['product_id', 'fecha'])['tn']\n",
    "           .sum()\n",
    "           .sort_index()\n",
    "           .groupby(level=0))\n",
    "\n",
    "# 6) Generar un CSV por cada ventana m√≥vil\n",
    "for w in WINDOWS:\n",
    "    pred = (serie.apply(lambda s: s.tail(w).mean())\n",
    "                  .reset_index()\n",
    "                  .groupby('product_id', as_index=False)['tn']\n",
    "                  .last())\n",
    "\n",
    "    # Unir con la lista y rellenar faltantes\n",
    "    pred = lista.merge(pred, on='product_id', how='left')\n",
    "    pred['tn'] = pred['tn'].fillna(0).round(5)\n",
    "\n",
    "    assert len(pred) == 780, f\"Ventana {w}: deber√≠an ser 780 filas\"\n",
    "\n",
    "    # Guardar\n",
    "    archivo = CARPETA_SALIDA / f\"submission_t780_win{w}.csv\"\n",
    "    pred.to_csv(archivo, index=False, float_format=\"%.5f\")\n",
    "    print(f\"‚úÖ CSV ventana {w} guardado en {archivo.name}\")\n",
    "\n",
    "print(\"üèÅ Listo: se generaron los 5 archivos.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f000851",
   "metadata": {},
   "source": [
    "arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ccb6b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting statsmodels\n",
      "  Using cached statsmodels-0.14.4-cp313-cp313-win_amd64.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in c:\\users\\equipo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from statsmodels) (2.2.6)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in c:\\users\\equipo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from statsmodels) (1.15.3)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in c:\\users\\equipo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from statsmodels) (2.2.3)\n",
      "Requirement already satisfied: patsy>=0.5.6 in c:\\users\\equipo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from statsmodels) (1.0.1)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\equipo\\appdata\\roaming\\python\\python313\\site-packages (from statsmodels) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\equipo\\appdata\\roaming\\python\\python313\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\equipo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\equipo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\equipo\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\n",
      "Using cached statsmodels-0.14.4-cp313-cp313-win_amd64.whl (9.8 MB)\n",
      "Installing collected packages: statsmodels\n",
      "Successfully installed statsmodels-0.14.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b187f16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CSV ARIMA (respaldo 12 m) guardado en: C:\\Maestria\\Labo 3\\submission_t780_arima.csv ‚Äî filas: 780\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ CONFIG ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "RUTA_VENTAS     = Path(r\"C:\\Maestria\\Labo 3\\sell-in.txt\")\n",
    "RUTA_LISTA_780  = Path(r\"C:\\Maestria\\Labo 3\\780_a_predecir.txt\")\n",
    "CARPETA_SALIDA  = Path(r\"C:\\Maestria\\Labo 3\")\n",
    "ARCHIVO_SALIDA  = CARPETA_SALIDA / \"submission_t780_arima.csv\"\n",
    "\n",
    "ARIMA_ORDER     = (1, 1, 1)\n",
    "FALLBACK_MESES  = 12                 # ‚Üê ahora la media es sobre 12 meses\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "\n",
    "# 1) Leer hist√≥rico de ventas\n",
    "df = pd.read_csv(RUTA_VENTAS, sep=None, engine=\"python\")\n",
    "\n",
    "# 2) Leer lista exacta de 780 product_id\n",
    "with open(RUTA_LISTA_780, 'r', encoding='utf-8') as f:\n",
    "    product_ids = [int(line.strip()) for line in f\n",
    "                   if line.strip() and not line.lower().startswith('product')]\n",
    "\n",
    "lista = pd.DataFrame({'product_id': product_ids})\n",
    "\n",
    "# 3) Preparar campo fecha\n",
    "df['periodo'] = df['periodo'].astype(str).str.zfill(6)\n",
    "df['anio']    = df['periodo'].str[:4].astype(int)\n",
    "df['mes']     = df['periodo'].str[4:6].astype(int)\n",
    "df['fecha']   = pd.to_datetime(df['anio'].astype(str)+df['mes'].astype(str)+'01',\n",
    "                               format='%Y%m%d')\n",
    "\n",
    "# 4) Filtrar s√≥lo los 780 SKU\n",
    "df = df[df['product_id'].isin(product_ids)]\n",
    "\n",
    "# 5) Serie mensual por SKU\n",
    "mensual = (df.groupby(['product_id', 'fecha'])['tn']\n",
    "             .sum()\n",
    "             .sort_index())\n",
    "\n",
    "# 6) Forecast por SKU\n",
    "predicciones = []\n",
    "for pid in product_ids:\n",
    "    serie = mensual.loc[pid] if pid in mensual.index.get_level_values(0) else pd.Series()\n",
    "    serie = serie.asfreq('MS', fill_value=0)\n",
    "\n",
    "    if serie.shape[0] < 4 or serie.sum() == 0:\n",
    "        y_hat = serie.tail(1).values[0] if not serie.empty else 0.0\n",
    "    else:\n",
    "        try:\n",
    "            model = ARIMA(serie, order=ARIMA_ORDER).fit()\n",
    "            y_hat = model.forecast(1).iloc[0]\n",
    "        except Exception:\n",
    "            y_hat = serie.tail(FALLBACK_MESES).mean()\n",
    "\n",
    "    predicciones.append((pid, max(0, round(float(y_hat), 5))))\n",
    "\n",
    "pred = pd.DataFrame(predicciones, columns=['product_id', 'tn'])\n",
    "\n",
    "# 7) Guardar CSV\n",
    "pred.to_csv(ARCHIVO_SALIDA, index=False, float_format=\"%.5f\")\n",
    "print(f\"‚úÖ CSV ARIMA (respaldo 12 m) guardado en: {ARCHIVO_SALIDA.resolve()} ‚Äî filas: {len(pred)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70260e2",
   "metadata": {},
   "source": [
    "ARIMA CON VENTANAS de otros meses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c02e083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CSV ventana 1 guardado ‚Üí submission_t780_arima_win1.csv\n",
      "‚úÖ CSV ventana 3 guardado ‚Üí submission_t780_arima_win3.csv\n",
      "‚úÖ CSV ventana 6 guardado ‚Üí submission_t780_arima_win6.csv\n",
      "‚úÖ CSV ventana 9 guardado ‚Üí submission_t780_arima_win9.csv\n",
      "üèÅ Listo: se generaron los 4 archivos con ARIMA + fallback din√°mico.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ CONFIG ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "RUTA_VENTAS     = Path(r\"C:\\Maestria\\Labo 3\\sell-in.txt\")\n",
    "RUTA_LISTA_780  = Path(r\"C:\\Maestria\\Labo 3\\780_a_predecir.txt\")\n",
    "CARPETA_SALIDA  = Path(r\"C:\\Maestria\\Labo 3\")\n",
    "VENTANAS        = [1, 3, 6, 9]           # ‚Üê ventanas a probar\n",
    "ARIMA_ORDER     = (1, 1, 1)\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "\n",
    "# 1) Leer hist√≥rico de ventas\n",
    "df = pd.read_csv(RUTA_VENTAS, sep=None, engine=\"python\")\n",
    "\n",
    "# 2) Leer lista exacta de 780 product_id\n",
    "with open(RUTA_LISTA_780, 'r', encoding='utf-8') as f:\n",
    "    product_ids = [int(line.strip()) for line in f\n",
    "                   if line.strip() and not line.lower().startswith('product')]\n",
    "\n",
    "lista_ids = pd.DataFrame({'product_id': product_ids})\n",
    "\n",
    "# 3) Preparar campo fecha\n",
    "df['periodo'] = df['periodo'].astype(str).str.zfill(6)\n",
    "df['anio']    = df['periodo'].str[:4].astype(int)\n",
    "df['mes']     = df['periodo'].str[4:6].astype(int)\n",
    "df['fecha']   = pd.to_datetime(df['anio'].astype(str)+df['mes'].astype(str)+'01', format='%Y%m%d')\n",
    "\n",
    "# 4) Filtrar los 780 SKU\n",
    "df = df[df['product_id'].isin(product_ids)]\n",
    "\n",
    "# 5) Serie mensual por SKU\n",
    "mensual = (df.groupby(['product_id', 'fecha'])['tn']\n",
    "             .sum()\n",
    "             .sort_index())\n",
    "\n",
    "# 6) Generar un CSV por cada ventana de respaldo\n",
    "for ventana in VENTANAS:\n",
    "    predicciones = []\n",
    "\n",
    "    for pid in product_ids:\n",
    "        serie = mensual.loc[pid] if pid in mensual.index.get_level_values(0) else pd.Series()\n",
    "        serie = serie.asfreq('MS', fill_value=0)\n",
    "\n",
    "        # fallback si la serie es muy corta\n",
    "        if serie.shape[0] < 4 or serie.sum() == 0:\n",
    "            y_hat = serie.tail(1).values[0] if not serie.empty else 0.0\n",
    "        else:\n",
    "            try:\n",
    "                model = ARIMA(serie, order=ARIMA_ORDER).fit()\n",
    "                y_hat = model.forecast(1).iloc[0]\n",
    "            except Exception:\n",
    "                y_hat = serie.tail(ventana).mean()\n",
    "\n",
    "        predicciones.append((pid, max(0, round(float(y_hat), 5))))\n",
    "\n",
    "    pred = pd.DataFrame(predicciones, columns=['product_id', 'tn'])\n",
    "    archivo = CARPETA_SALIDA / f\"submission_t780_arima_win{ventana}.csv\"\n",
    "    pred.to_csv(archivo, index=False, float_format=\"%.5f\")\n",
    "    print(f\"‚úÖ CSV ventana {ventana} guardado ‚Üí {archivo.name}\")\n",
    "\n",
    "print(\"üèÅ Listo: se generaron los 4 archivos con ARIMA + fallback din√°mico.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
